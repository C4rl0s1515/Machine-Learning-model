
# Machine Learning aplicado al rendimiento acad√©mico: EDA y modelado predictivo

## 1. üìù Introducci√≥n

Este repositorio contiene un proyecto completo de an√°lisis y modelado predictivo aplicado al rendimiento acad√©mico de un grupo de estudiantes, con el objetivo de identificar los factores m√°s relevantes asociados a la obtenci√≥n de resultados positivios, y as√≠ poder desarrollar dos modelos que sean capaces, de predecir la calificaci√≥n final y clasificar si el estudiante aprueba o suspende. 

El conjunto de datos incluye variables relacionadas con h√°bitos, contexto del alumno y varias caracter√≠sticas vinculadas a la forma de estudio. Las variables objetivo del proyecto son `nota_final` para el ejercicio de regresi√≥n y `aprobado` para el ejercicio de clasificaci√≥n, donde **aprobado** toma el valor de **1** si la nota es mayor o igual a 60 y **suspenso** donde toma el valor de **0** cuando la nota es inferior a 60 .

El proyecto se desarrolla de forma estructurada siguiendo un flujo de trabajo profesional. En primer lugar, se realiza un an√°lisis exploratorio de datos para comprender la estructura del dataset, revisar la calidad del dato y estudiar el comportamiento de las variables mediante an√°lisis univariante y bivariante, incluyendo visualizaciones y relaciones con las variables objetivo. 

A continuaci√≥n, se realiza una fase de preprocesamiento basada en **Pipelines**, donde se define el tratamiento de valores nulos, el escalado de variables num√©ricas y la codificaci√≥n de variables categ√≥ricas, preparando el dataset para el entrenamiento de modelos sin que se prodizca fuga de informaci√≥n.

Posteriormente, se aborda el modelado en dos bloques. Por un lado, se entrena y valida un modelo de **regresi√≥n** para predecir `nota_final`, comparando un baseline con modelos lineales y regularizados, y seleccionando el modelo final en base a m√©tricas y validaci√≥n cruzada. 

Por otro lado, se entrena y valida un modelo de **clasificaci√≥n** para predecir `aprobado`, evaluando el impacto del desbalance de clases mediante m√©tricas adecuadas y analizando el efecto del ajuste de umbral para controlar el compromiso entre detectar suspensos y minimizar falsos resultados. Finalmente, se guardan los modelos entrenados para su reutilizaci√≥n y se procede a documentar las conclusiones y decisiones tomadas a lo largo del proceso.

## **2. ‚úÖ Objetivos del An√°lisis**

### Objetivo general

Realizar un an√°lisis completo del rendimiento acad√©mico de un grupo de estudiantes que permita comprender la estructura y calidad del conjunto de datos, estudiando la distribuci√≥n y relaci√≥n de las variables con el resultado obtenido, as√≠ como desarrollar modelos predictivos para estimar la `nota_final` y clasificar si a `aprobado`, obteniendo una base s√≥lida y reproducible para la toma de decisiones y evaluaci√≥n de resultados.

### Objetivos espec√≠ficos

- ***An√°lisis preliminar***: Se realiza una revisi√≥n inicial del dataset para identificar su estructura, tama√±o, tipos de variables, rangos y primeras se√±ales de posibles incoherencias, adem√°s de revisar la presencia de valores duplicados o nulos que puedan afectar al an√°lisis posterior.

- ***Limpieza y transformaci√≥n***: Se prepara el dataset para el modelado garantizando la coherencia y calidad de los datos, revisando los rangos, definiendo el tratamiento de valores nulos y dejando el conjunto de datos en condiciones adecuadas para el an√°lisis y el preprocesamiento posterior.

- ***An√°lisis exploratorio de datos (EDA)***: Se estudia de forma detallada el comportamiento del dataset mediante un an√°lisis univariante y bivariante, incorporando visualizaciones y medidas descriptivas. Se analiza la relaci√≥n de las variables predictoras con las variables objetivo `nota_final` y `aprobado`, incluyendo las correlaciones y comparativas por grupos para detectar se√±ales √∫tiles.

- ***Preprocesamiento para modelado***: construir un flujo de preprocesamiento reproducible basado en Pipelines que incluya imputaci√≥n, escalado de variables num√©ricas y codificaci√≥n de variables categ√≥ricas, asegurando que el ajuste se realiza √∫nicamente con el conjunto de entrenamiento para evitar fuga de informaci√≥n.

- ***Modelado de regresi√≥n***: Se entrenan, validan y comparan los modelos para predecir la varibale `nota_final`, estableciendo un baseline, evaluando modelos lineales y regularizados, y seleccionando el modelo final seg√∫n m√©tricas y validaci√≥n cruzada.

- ***Modelado de clasificaci√≥n***: Se entrenan, validan y comparan los modelos para predecir el `aprobado`, considerando el desbalance de clases mediante m√©tricas adecuadas, adem√°s se evalua el comportamiento del modelo con curvas ROC/PR, matriz de confusi√≥n y, si es necesario, se ajuste e√± umbral para analizar el compromiso entre detectar suspensos y minimizar falsas alarmas.

## 3. ‚öôÔ∏è Estructura del Proyecto

```
|------ data # Carpeta que contiene los datos utilizados en el proyecto.
  |---- 1.raw # Datos originales sin procesar, tal y como se proporcionan para el an√°lisis.
    |--- dataset_estudiantes.csv # Dataset base con informaci√≥n del grupo de estudiantes.
|------ models # Modelos entrenados y guardados para reutilizaci√≥n y despliegue.
    |--- 0.1_modelo_regresion_ridge.pkl # Modelo final de regresi√≥n Ridge para predecir `nota_final`, incluye el Pipeline de preprocesamiento.
    |--- 0.2_modelo_clasificacion_logreg.pkl # Modelo final de clasificaci√≥n con Regresi√≥n Log√≠stica para predecir `aprobado`, incluye el Pipeline.
    |--- 0.3_modelo_clasificacion_logreg_threshold.pkl # Versi√≥n del modelo de clasificaci√≥n que guarda modelo y umbral final seleccionado.
|------ notebook # Notebooks con el desarrollo del an√°lisis.
    |--- 0.1_EDA.ipynb # An√°lisis exploratorio del dataset, calidad del dato, visualizaciones y relaciones con los objetivos.
    |--- 0.2_Preprocesamiento.ipynb # Definici√≥n de variables, Pipelines de transformaci√≥n y preparaci√≥n de train/test para regresi√≥n y clasificaci√≥n.
    |--- 0.3_Entrenamiento_y_validacion_modelo_regresion.ipynb # Entrenamiento, validaci√≥n y selecci√≥n del modelo final de regresi√≥n, con m√©tricas y gr√°ficos.
    |--- 0.4_Entrenamiento_y_validacion_modelo_clasificacion.ipynb # Entrenamiento, validaci√≥n y selecci√≥n del modelo final de clasificaci√≥n, incluyendo m√©tricas, curvas y ajuste de umbral.
|------ README.md # Documento principal con la descripci√≥n del proyecto, estructura, ejecuci√≥n y resultados principales.
|------ requirements.txt # Listado de dependencias necesarias para instalar el entorno y reproducir el proyecto.    
```

## 4. üìå Descripci√≥n del Conjunto de Datos

El conjunto de datos `dataset_estudiantes.csv` recoge informaci√≥n del rendimiento acad√©mico de un grupo de estudiantes junto con variables relacionadas con sus h√°bitos y entorno de estudio, con el objetivo de analizar qu√© factores se asocian con el desempe√±o y apoyar la construcci√≥n de modelos predictivos. A continuaci√≥n se describen las variables incluidas en el an√°lisis exploratorio.

- **horas_estudio_semanal**: N√∫mero de horas de estudio a la semana.

- **nota_anterior**: Nota que obtuvo el alumno en la convocatoria anterior.

- **tasa_asistencia**: Tasa de asistencia a clase en porcentaje.

- **horas_sueno**: Promedio de horas que duerme el alumno al d√≠a.

- **edad**: Edad del alumno.

- **nivel_dificultad**: Dificultad del alumno para el estudio.

- **tiene_tutor**: Indica si el alumno tiene tutor o no.

- **horario_estudio_preferido**: Horario de estudio preferido por el alumno.

- **estilo_aprendizaje**: Forma de estudio que emplea el alumno.

#### **Variables objetivo**

- Para regresi√≥n: **nota_final** (variable continua entre 0 y 100)

- Para clasificaci√≥n: **aprobado** (variable binaria: 1 si la nota es ‚â• 60, y 0 en caso contrario)

## 5. üíæ Instalaci√≥n, requisitos y reproducci√≥n del proyecto

#### **5.1 Requisitos**

- Versi√≥n de Python recomendada: 3.12

- Entorno probado en: Windows

- Gestor de paquetes: pip

- Ejecuci√≥n del proyecto: Jupyter Notebook

#### **5.2 Dependencias principales**

- Pandas y NumPy: carga, manipulaci√≥n, limpieza y transformaci√≥n de datos.

- Matplotlib y Seaborn: visualizaciones descriptivas del EDA (distribuciones, boxplots, comparativas).

- scikit-learn: preprocesamiento con Pipelines, entrenamiento y validaci√≥n de modelos, m√©tricas y validaci√≥n cruzada.

- joblib: guardado y carga de modelos entrenados.

#### **5.3 Instalaci√≥n**

```
pip install -r requirements.txt
```
#### **5.4 Reproducir el proyecto**

**1. Datos originales**

- `data/1.raw/dataset_estudiantes.csv`

**2. Ejecuta los notebooks en este orden**

1. `notebooks/01_EDA.ipynb`

- An√°lisis preliminar, calidad del dato y EDA univariante y bivariante con respecto a `nota_final` y `aprobado`.

2. `notebooks/02_Preprocesamiento.ipynb`

- Definici√≥n de variables objetivo y predictoras, creaci√≥n de Pipelines de transformaci√≥n, imputaci√≥n, escalado y one-hot encoding y preparaci√≥n del split de train y test para regresi√≥n y clasificaci√≥n.

3. `notebooks/03_Regresion.ipynb`

- Entrenamiento, validaci√≥n y comparaci√≥n de modelos de regresi√≥n para `nota_final`. Selecci√≥n y guardado del modelo final.

4. `notebooks/04_Clasificacion.ipynb`

- Entrenamiento, validaci√≥n y comparaci√≥n de modelos de clasificaci√≥n para `aprobado`, incluyendo matriz de confusi√≥n, curvas ROC/PR y ajuste de umbral. Selecci√≥n y guardado del modelo final.

**3. Archivos generados**

Como resultado del proceso se generan:

- `models/0.1_modelo_regresion_ridge.pkl`

- `models/0.2_modelo_clasificacion_logreg.pkl`

- `models/0.3_modelo_clasificacion_logreg_threshold.pkl`

## 6. üìÅ Recap Sesiones

**Sesi√≥n 1**

- Creaci√≥n del repositorio en GitHub.

- Definici√≥n y creaci√≥n de la estructura de carpetas del proyecto.

- Creaci√≥n del archivo **README.md** como base de documentaci√≥n del repositorio.

- Incorporaci√≥n del dataset original `dataset_estudiantes.csv` en la carpeta **data/1.raw/**.

**Sesi√≥n 2**

- Creaci√≥n del notebook `'0.1_EDA.ipynb'`.

- Carga del dataset y revisi√≥n inicial de estructura: dimensiones, columnas y tipos de dato.

- Evaluaci√≥n de calidad del dato: duplicados, valores nulos y visualizaci√≥n de nulos.

- An√°lisis univariante: variables num√©ricas y categ√≥ricas con estad√≠sticos y gr√°ficos.

- An√°lisis bivariante: relaci√≥n de variables con `nota_final` y `aprobado` mediante boxplots, scatterplots y barplots.

- An√°lisis de correlaci√≥n: matriz de correlaci√≥n y heatmap para variables num√©ricas.

- Conclusiones del EDA: variables m√°s relevantes y decisiones preliminares para el preprocesamiento.

**Sesi√≥n 3**

- Creaci√≥n del notebook `'0.2_Preprocesamiento_ipynb'`.

- Definici√≥n de objetivos `nota_final` y `aprobado` y separaci√≥n de predictores evitando fuga de informaci√≥n.

- Identificaci√≥n de columnas num√©ricas y categ√≥ricas.

- Construcci√≥n del pipeline num√©rico: imputaci√≥n por mediana y escalado con **StandardScaler**.

- Construcci√≥n del pipeline categ√≥rico: imputaci√≥n con valor constante y **OneHotEncoder**.

- Integraci√≥n con **ColumnTransformer** para aplicar cada transformaci√≥n a sus columnas.

- Preparaci√≥n del split train/test para regresi√≥n y clasificaci√≥n, con estratificaci√≥n en clasificaci√≥n.

- Verificaci√≥n final: shapes de train/test y comprobaci√≥n de proporciones de clase en `aprobado`.

**Sesi√≥n 4**

- Creaci√≥n del notebook `0.3_Entrenamiento_y_validacion_modelo_regresion.ipynb`.

- Redefinici√≥n de variables, preprocesamiento y split para ejecutar el notebook de forma independiente.

- Creaci√≥n de funci√≥n **eval_regression** para calcular MAE, RMSE y R¬≤.

- Modelo baseline: entrenamiento y evaluaci√≥n con **DummyRegressor**.

- Modelo de regresi√≥n lineal: **LinearRegression** con pipeline completo y comparaci√≥n train/test.

- Validaci√≥n cruzada: evaluaci√≥n de **LinearRegression** con KFold y m√©tricas medias.

- Ajuste de hiperpar√°metros: **Ridge** m√°s **GridSearchCV** para seleccionar el mejor **alpha**.

- Evaluaci√≥n final en test del mejor **Ridge** y selecci√≥n del modelo final.

- Visualizaciones de diagn√≥stico: real vs predicho y residuos.

- Guardado del modelo final en **models/** como `0.1_modelo_regresion_ridge.pkl`.

**Sesi√≥n 5**

- Creaci√≥n del notebook `0.4_Entrenamiento_y_validacion_modelo_clasificacion.ipynb`.

- Redefinici√≥n de variables, preprocesamiento y split para clasificaci√≥n.

- Creaci√≥n de funci√≥n **eval_classification** para accuracy, precision, recall, F1 y ROC-AUC.

- Modelo baseline: entrenamiento y evaluaci√≥n con **DummyClassifier**.

- Modelo principal: **LogisticRegression** con pipeline y **class_weight="balanced"**.

- Validaci√≥n cruzada: **StratifiedKFold** con m√©tricas medias **incluyendo ROC-AUC**.

- Ajuste de hiperpar√°metros: **GridSearchCV** para seleccionar **C** y comparaci√≥n L1 vs L2.

- Evaluaci√≥n del modelo final: matriz de confusi√≥n, classification report y curva ROC/PR.

- Ajuste de umbral: tabla de m√©tricas por umbral para clase 0 y 1 y selecci√≥n del umbral final.

- Evaluaci√≥n final con el umbral elegido y documentaci√≥n del compromiso entre m√©tricas.

- Guardado del modelo final de clasificaci√≥n en **models/** como `0.2_modelo_clasificacion_logreg.pkl`.

- Guardado de la versi√≥n del modelo con umbral final en **models/** como `0.3_modelo_clasificacion_logreg_threshold.pkl`.

**Sesi√≥n 6**

- Creaci√≥n del archivo **requirements.txt** con las dependencias necesarias para reproducir el proyecto.

- Redacci√≥n final del **README.md**, documentando objetivos, estructura del proyecto, dependencias, ejecuci√≥n y resultados principales.

- Inclusi√≥n del apartado de instalaci√≥n y reproducci√≥n, indicando el orden de ejecuci√≥n de los notebooks y los archivos generados.

- Revisi√≥n final de formato y del repositorio para la entrega en GitHub.

## 7. üìä Resultados y Conclusiones

En este proyecto se ha realizado un an√°lisis exploratorio que permitie comprender la estructura del dataset y detectar patrones relevantes antes de desarrollar los modelos. A nivel descriptivo, las variables num√©ricas muestran comportamientos coherentes con el contexto acad√©mico y, en general, no se observaron inconsistencias graves en rangos. Las visualizaciones univariantes y bivariantes ayudan a identificar qu√© variables aportan mayor informaci√≥n respecto al rendimiento final.

En el estudio de relaciones con la variable objetivo de regresi√≥n `nota_final`, se observa que las variables m√°s informativas son **horas de estudio semanal**, **nota previa** y **tasa de asistencia**. Esto se refleja tanto en las visualizaciones gr√°ficas, como en los an√°lisis num√©ricos de correlaci√≥n, donde estas variables mantienen asociaciones positivas m√°s consistentes con el rendimiento.

En cambio, variables como **edad** muestran una relaci√≥n pr√°cticamente nula con el rendimiento obtenido, por lo que su aportaci√≥n al modelo se esperaba que fuera limitada. **Horas de sue√±o** presenta una asociaci√≥n d√©bil, indicando que, en el dataset, su contribuci√≥n parece menor en comparaci√≥n con variables m√°s directamente ligadas al estudio, que son las que explican mejor las relaciones observadas en el rendimiento.

Para la variable objetivo de clasificaci√≥n `aprobado`, el EDA tambi√©n evidencia la importancia de estudiar el balance de clases. Se identifica un desbalance marcado con predominio de aprobados, lo que implica que m√©tricas como la **accuracy** pueden resultar enga√±osas si el modelo aprende a predecir mayoritariamente la clase positiva. Por este motivo, el proyecto incorpora m√©tricas complementarias y an√°lisis por clase como la **matriz de confusi√≥n** y la **classification report**, para evaluar la utilidad real del clasificador.

En conjunto, el EDA nos permite tomar decisiones de preprocesamiento con criterio y nos muestra que la regresi√≥n puede apoyarse en relaciones relativamente estables, mientras que la clasificaci√≥n requiere mayor atenci√≥n por el existente desbalanceo de clases y por el intercambio entre captar m√°s suspensos o reducir errores de clasificaci√≥n.

El preprocesamiento se dise√±a con un enfoque reproducible y profesional mediante **Pipeline** y **ColumnTransformer**, separando tratamientos para variables num√©ricas y categ√≥ricas. Esto permite asegurar consistencia entre experimentos, especialmente durante las fases de modelado, y evitar fuga de informaci√≥n al ajustar transformaciones √∫nicamente con el conjunto de entrenamiento.

Variables num√©ricas se tratan mediante imputaci√≥n por mediana como estrategia robusta y posteriormente escalado con **StandardScaler**, √∫til para modelos lineales y regularizados, mientras que a las variables categ√≥ricas se les aplica una imputaci√≥n con valor constante y codificaci√≥n mediante **One-Hot Encoding**, transformando las categor√≠as en variables binarias y permitiendo que los modelos trabajen con un formato totalmente num√©rico.

La preparaci√≥n del split, se realiza mediante la partici√≥n de train y test para regresi√≥n y para clasificaci√≥n. En clasificaci√≥n se utiliza una divisi√≥n estratificada para mantener la proporci√≥n de clases y evitar que el desbalance se agrave en train o test. A continuaci√≥n como verificaci√≥n t√©cnica, se procede a comprobar el aumento de dimensionalidad tras aplicar el **One-Hot Encoding**, confirmando que el preprocesamiento transforma correctamente el dataset a un formato apto para modelos de machine learning.

En la fase de **regresi√≥n**, el objetivo se enfoca en predecir `nota_final` con un proceso de comparaci√≥n progresivo, mediante un baseline, un modelo lineal y un modelo regularizado.

El **baseline** se utiliza como referencia m√≠nima, su rendimiento es claramente bajo, con un **R¬≤** cercano a **0** o **negativo**, lo que indica que el modelo no explica la variabilidad del objetivo y que pr√°cticamente se limita a predecir un valor promedio. Su funci√≥n en el proyecto es establecer un punto de partida para validar que los modelos posteriores realmente aportan mejora.

La **regresi√≥n lineal** supone una mejora clara frente al **baseline**. Las m√©tricas en **train** y **test** son relativamente consistentes, lo que sugiere que el modelo generaliza de forma razonable. El modelo consige un **R¬≤** en torno a **0.35** y **0.40**, mostrando que parte del rendimiento acad√©mico s√≠ puede explicarse con las variables disponibles, aunque tambi√©n existe una fracci√≥n importante no capturada, esto puede deberse a posibles variables no incluidas, ruido o relaciones no lineales.

El modelo final seleccionado tras el ajuste del hiperparametro **alpha** con validaci√≥n cruzada es **Ridge**, ya que la regularizaci√≥n permiti√≥ estabilizar los coeficientes y mejorar ligeramente la generalizaci√≥n, obteniendo valores finales consistentes con un **MAE** de **5.846**, un **RMSE** de **7.206** y un **R¬≤** de **0.365**, lo que nos indica que en promedio el error absoluto en la predicci√≥n de la nota final ronda los **6 puntos**, y que el modelo logra explicar aproximadamente un **36.5%** de la variabilidad de `nota_final`. Adem√°s, los gr√°ficos de diagn√≥stico muestran un comportamiento razonable, los errores se distribuyen alrededor de cero sin patrones extremos dominantes, aunque sigue existiendo dispersi√≥n, especialmente en ciertos rangos de nota, lo que sugiere l√≠mites naturales del modelo lineal para capturar toda la complejidad del rendimiento.

Como resultado, se guarda el modelo final como `0.1_modelo_regresion_ridge.pkl`, incluyendo el Pipeline completo, permitiendo reproducir el mismo preprocesamiento y predicci√≥n con datos nuevos.

En la fase de **clasificaci√≥n** tiene como objetivo predecir `aprobado`, con especial atenci√≥n al desbalance entre clases y al an√°lisis del rendimiento por clase.

El baseline alcanza una **accuracy** alta debido a que predice siempre la clase mayoritaria. Sin embargo, este resultado no implica capacidad real de discriminaci√≥n, ya que tenemos un dataset con muchos aprobados, acertar ‚Äúaprobado‚Äù casi siempre da una **accuracy** elevada aunque el modelo sea in√∫til para detectar suspensos, por esta raz√≥n se utiliza √∫nicamente como referencia.

Eln el modelo de **regresi√≥n log√≠stica** se incorpora la **class_weight**=**"balanced"** para compensar el desbalance, a diferencia del **baseline**, el modelo muestra capacidad real de separaci√≥n, lo que se reflejada en **ROC-AUC** con un valor de **0.802** en test.
Este valor indica que el ranking de probabilidades es claramente mejor que el azar y que el modelo distingue razonablemente entre aprobados y suspensos.

Al revisar el **classification report**, se observa un rendimiento alto en la clase mayoritaria **aprobado**, mientras que la clase minoritaria **suspenso** present√≥ m√©tricas m√°s bajas, esto es esperable en un escenario desbalanceado, ya que mejorar la detecci√≥n de suspensos suele implicar el aumento de falsos positivos.

Para profundizar en el comportamiento del clasificador, se construye una tabla de umbrales evaluando m√©tricas para ambas clases, esto permite visualizar c√≥mo cambia el modelo cuando se vuelve m√°s estricto o m√°s permisivo a la hora de asignar la clase **aprobado**.
Con el umbral seleccionado de **0.40**, el modelo mantiene un rendimiento muy alto para aprobados y minimiza falsas alarmas de suspenso, con un **precision** de **suspenso** de **0.80**, un **recall** de **suspenso** de **0.20**, lo que significa que cuando el modelo predice suspenso suele acertar, pero detecta pocos suspensos reales. Esta es una decisi√≥n conservadora que prioriza el intentar evitar clasificar **aprobados** como **suspenso**, lo que aumenta la **accuracy** global pero limita la sensibilidad hacia la clase minoritaria. 

Para finalizar este bloque deja documentado la clasificaci√≥n desbalanceada y permitie justificar con datos el umbral final seleccionado, procediendose a guardar las dos versiones del modelo, como `0.2_modelo_clasificacion_logreg.pkl` para el modelo base entrenado con log√≠stica y `0.3_modelo_clasificacion_logreg_threshold.pkl` para el modelo con el umbral final incorporado.

Para concluir podemos decir que el rendimiento acad√©mico en este dataset est√° principalmente asociado a **horas de estudio**, **nota previa** y **asistencia**, lo que es coherente con un contexto educativo y se confirma tanto en el EDA como en el modelado.

En **regresi√≥n**, los modelos lineales explican una parte moderada del rendimiento, y la regularizaci√≥n ofrece un equilibrio estable con errores medios alrededor de **6 puntos** en la predicci√≥n de la nota final.

En clasificaci√≥n, el desbalance de clases obliga a evaluar m√°s all√° de la **accuracy**, mientras que la regresi√≥n log√≠stica logra buena discriminaci√≥n global con un **ROC-AUC** de **0.802**, pero la detecci√≥n de suspensos sigue siendo la parte m√°s dif√≠cil.

El ajuste de umbral es clave para decidir qu√© se prioriza, si detectar m√°s suspensos o reducir falsas alarmas mejorando el rendimiento global, durante el proyecto se justifica esta decisi√≥n y se selecciona un umbral final coherente con el criterio aplicado.

El uso de **Pipelines** y **ColumnTransformer** garantiza un flujo reproducible, ya que reduce errores y permite entrenar y aplicar modelos de forma consistente.

En conjunto, el proyecto cubre todas las etapas del flujo de **machine learning** y deja el repositorio preparado para reproducir el an√°lisis, entrenar los modelos y revisar los resultados.

## 8. üñäÔ∏è Contribuciones

Cualquier contribucion es bien venida, si quiere colaborar en el proyecto, abre un pull request.

## 9. üíª Autores

Carlos Hernando

https://github.com/C4rl0s1515